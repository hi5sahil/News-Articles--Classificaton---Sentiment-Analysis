{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Setting up PySpark as stand alone on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Library and setting environment path\n",
    "import os\n",
    "import sys\n",
    "# set the path \n",
    "\n",
    "sparkPath = \"C:\\spark-2.0.2-bin-hadoop2.7\"\n",
    "\n",
    "os.environ['SPARK_HOME'] = sparkPath\n",
    "sys.path.append(sparkPath + '/bin')\n",
    "sys.path.append(sparkPath + '/python')\n",
    "sys.path.append(sparkPath + '/python/pyspark')\n",
    "sys.path.append(sparkPath + '/python/pyspark/lib')\n",
    "sys.path.append(sparkPath + '/python/pyspark/lib/pyspark.zip')\n",
    "sys.path.append(sparkPath + '/python/pyspark/lib/py4j-0.10.3-src.zip')\n",
    "sys.path.append(\"C:/Program Files (x86)/Java/jre1.8.0_111/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing VaderSentiment (A library for extracting sentiment from text, considers word order, context & punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "nb_stdout = sys.stdout\n",
    "#from vaderSentiment.vaderSentiment import sentiment as vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import time\n",
    "import datetime\n",
    "sys.stdout = nb_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to decompose sentiment into postive, negative and neutral part as well as extract the overall sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def senti(para):\n",
    "    lines_list = tokenize.sent_tokenize(para)\n",
    "    \n",
    "    negList = []\n",
    "    neuList = []\n",
    "    posList = []\n",
    "    compoundList = []\n",
    "    for lines in lines_list:\n",
    "        negs = vaderSentiment(lines)['neg']\n",
    "        negList.append(negs)\n",
    "        neu = vaderSentiment(lines)['neu']\n",
    "        neuList.append(neu)\n",
    "        poss = vaderSentiment(lines)['pos']\n",
    "        posList.append(poss)\n",
    "        comps = vaderSentiment(lines)['compound']\n",
    "        compoundList.append(comps)\n",
    "        \n",
    "    sentiList = [np.array(negList).mean(),np.array(neuList).mean(),np.array(posList).mean(),np.array(compoundList).mean()]\n",
    "    return sentiList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data as RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "originalRDD=sc.textFile(\\\n",
    "\"file:///C:/Users/Sahil Gupta/Google Drive/Fall/Big Data/Big Data Project/NewsAggregatorDataset/newsCorpora.csv\")\\\n",
    ".map(lambda line: line.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'Fed official says weak data caused by weather, should not slow taper',\n",
       " u'http://www.latimes.com/business/money/la-fi-mo-federal-reserve-plosser-stimulus-economy-20140310,0,1312750.story\\\\?track=rss',\n",
       " u'Los Angeles Times',\n",
       " u'b',\n",
       " u'ddUyU0VZz0BRneMioxUPQVP6sIxvM',\n",
       " u'www.latimes.com',\n",
       " u'1394470370698']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consideredRDD = originalRDD.map(lambda fields:(fields[0],fields[1],fields[4],analyzer.polarity_scores(fields[1])['compound'],\\\n",
    "                                               time.strftime('%Y-%m-%d', time.gmtime(int(fields[7])/1000.0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering only the business articles. The following chunk of code was run for each of the four category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "businessRDD = consideredRDD.filter(lambda line: line[2] == 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'1',\n",
       " u'Fed official says weak data caused by weather, should not slow taper',\n",
       " u'b',\n",
       " -0.4404,\n",
       " '2014-03-10')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "businessRDD.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the aggregated sentiment by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggrSentiRDD = businessRDD.map(lambda line: (line[4], line[3])).reduceByKey(lambda v1,v2:v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countSentiRDD = businessRDD.map(lambda line: (line[4], 1)).reduceByKey(lambda v1,v2:v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "busineSentiRDD = aggrSentiRDD.join(countSentiRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2014-03-11', (-14.769699999999977, 1117))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busineSentiRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "busineSentiRDDFinal = busineSentiRDD.map(lambda line: (line[0], line[1][0]/line[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014-03-11', -0.013222649955237222),\n",
       " ('2014-03-18', -0.022615942028985387),\n",
       " ('2014-06-16', -0.1123684663536776),\n",
       " ('2014-04-17', 0.03348704177323086),\n",
       " ('2014-04-12', -0.025745797280593334)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busineSentiRDDFinal.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the RDD to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "busineSentiDF = sqlContext.createDataFrame(busineSentiRDDFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "busineSentiDataFrame = busineSentiDF.toPandas().rename(columns={'_1': 'Date', '_2': 'Overall Sentiment'}).groupby('Date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-10</th>\n",
       "      <td>-0.112655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-11</th>\n",
       "      <td>-0.013223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-13</th>\n",
       "      <td>-0.041790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-17</th>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-18</th>\n",
       "      <td>-0.022616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-19</th>\n",
       "      <td>-0.020367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-20</th>\n",
       "      <td>0.026327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-22</th>\n",
       "      <td>-0.144964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-23</th>\n",
       "      <td>0.051618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-24</th>\n",
       "      <td>0.016070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-25</th>\n",
       "      <td>-0.009726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-26</th>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>0.002032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-28</th>\n",
       "      <td>-0.066917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-29</th>\n",
       "      <td>-0.046911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-30</th>\n",
       "      <td>-0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>0.029445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>0.038517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-02</th>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-07</th>\n",
       "      <td>0.102856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-08</th>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-09</th>\n",
       "      <td>-0.223047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-11</th>\n",
       "      <td>0.010642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-12</th>\n",
       "      <td>-0.025746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-13</th>\n",
       "      <td>-0.123233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-14</th>\n",
       "      <td>0.032220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-15</th>\n",
       "      <td>0.021050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-16</th>\n",
       "      <td>0.118033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-17</th>\n",
       "      <td>0.033487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-18</th>\n",
       "      <td>0.011992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-23</th>\n",
       "      <td>0.014882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-24</th>\n",
       "      <td>-0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-25</th>\n",
       "      <td>-0.056477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-26</th>\n",
       "      <td>-0.047839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-27</th>\n",
       "      <td>-0.023628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-28</th>\n",
       "      <td>-0.081915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29</th>\n",
       "      <td>0.017953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>0.048507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-01</th>\n",
       "      <td>0.011557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-02</th>\n",
       "      <td>-0.081592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-03</th>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-04</th>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-05</th>\n",
       "      <td>0.017603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-06</th>\n",
       "      <td>-0.033678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07</th>\n",
       "      <td>-0.026906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-08</th>\n",
       "      <td>-0.035366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-09</th>\n",
       "      <td>0.004583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-10</th>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-15</th>\n",
       "      <td>-0.012441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-16</th>\n",
       "      <td>0.060926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-17</th>\n",
       "      <td>-0.043750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-18</th>\n",
       "      <td>0.041712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-29</th>\n",
       "      <td>0.059036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-30</th>\n",
       "      <td>0.029872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-31</th>\n",
       "      <td>-0.020949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-01</th>\n",
       "      <td>0.013768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-08</th>\n",
       "      <td>0.051490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-25</th>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-27</th>\n",
       "      <td>0.028923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-28</th>\n",
       "      <td>0.015741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Overall Sentiment\n",
       "Date                         \n",
       "2014-03-10          -0.112655\n",
       "2014-03-11          -0.013223\n",
       "2014-03-13          -0.041790\n",
       "2014-03-17           0.004762\n",
       "2014-03-18          -0.022616\n",
       "2014-03-19          -0.020367\n",
       "2014-03-20           0.026327\n",
       "2014-03-22          -0.144964\n",
       "2014-03-23           0.051618\n",
       "2014-03-24           0.016070\n",
       "2014-03-25          -0.009726\n",
       "2014-03-26           0.036989\n",
       "2014-03-27           0.002032\n",
       "2014-03-28          -0.066917\n",
       "2014-03-29          -0.046911\n",
       "2014-03-30          -0.002800\n",
       "2014-03-31           0.029445\n",
       "2014-04-01           0.038517\n",
       "2014-04-02           0.009200\n",
       "2014-04-07           0.102856\n",
       "2014-04-08          -0.001416\n",
       "2014-04-09          -0.223047\n",
       "2014-04-11           0.010642\n",
       "2014-04-12          -0.025746\n",
       "2014-04-13          -0.123233\n",
       "2014-04-14           0.032220\n",
       "2014-04-15           0.021050\n",
       "2014-04-16           0.118033\n",
       "2014-04-17           0.033487\n",
       "2014-04-18           0.011992\n",
       "...                       ...\n",
       "2014-06-23           0.014882\n",
       "2014-06-24          -0.003504\n",
       "2014-06-25          -0.056477\n",
       "2014-06-26          -0.047839\n",
       "2014-06-27          -0.023628\n",
       "2014-06-28          -0.081915\n",
       "2014-06-29           0.017953\n",
       "2014-06-30           0.048507\n",
       "2014-07-01           0.011557\n",
       "2014-07-02          -0.081592\n",
       "2014-07-03           0.007330\n",
       "2014-07-04           0.005718\n",
       "2014-07-05           0.017603\n",
       "2014-07-06          -0.033678\n",
       "2014-07-07          -0.026906\n",
       "2014-07-08          -0.035366\n",
       "2014-07-09           0.004583\n",
       "2014-07-10           0.047618\n",
       "2014-07-15          -0.012441\n",
       "2014-07-16           0.060926\n",
       "2014-07-17          -0.043750\n",
       "2014-07-18           0.041712\n",
       "2014-07-29           0.059036\n",
       "2014-07-30           0.029872\n",
       "2014-07-31          -0.020949\n",
       "2014-08-01           0.013768\n",
       "2014-08-08           0.051490\n",
       "2014-08-25           0.055883\n",
       "2014-08-27           0.028923\n",
       "2014-08-28           0.015741\n",
       "\n",
       "[102 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(busineSentiDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the sentiment as a time series in Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hi5sahil/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='hi5sahil', api_key='V2ZZuDdBR6IqM4cqbTM3')\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Business Sentiment over Time',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Overall Sentiment',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [go.Scatter(\n",
    "          x=list(busineSentiDataFrame.index),\n",
    "          y=list(busineSentiDataFrame['Overall Sentiment'].values),\n",
    "          line = dict(\n",
    "          color = ('darkgreen')))]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='axes-booleans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
